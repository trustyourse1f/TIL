# 9. 나이브 베이즈 분류기

## 나이브 베이즈 분류기란?

- 확률 기반 분류기
- 데이터가 각 클래스에 속할 예측 특징 확률을 계산
- 나이브(Naive) : 예측한 특징이 상호 독립적이라는 가정 하에 확률 계산을 단순화
- 베이즈(Bayes) : 입력 특징이 클래스 전체의 확률 분포 대비 특정 클래스에 속할 확률을 베이즈 정리를 기반으로 계산

- 샘플 데이터가 k에 속하는 사건의 확률 P(y_k)는 관측값의 특징에 대한 지식없이 클래스가 어떻게 분포되어 있는지 나타냄 -> 사전 확률
- 사전 확률은 사전에 결정되어 있거나, 학습 샘플 데이터를 이용해 학습시킬 수도 있음
- P(y_k|x) 는 관측값에 대해 외부 지슥을 이용한 '사후 확률'
- P(y_k|x) 클래스 y_k에 속한 샘플 데이터가 주어졌을 때 n개의 특징에 대한 결합 분포를 나타냄 -> 유사가능도
- 나이브 베이즈는 특징 간 서로 독립이라는 가정이 있으므로, n개의 특징에 대한 결합 조건부 분포는 특징들의 분포를 곱한 것으로 표현할 수 있음

![image-20220514155254267](https://user-images.githubusercontent.com/102509786/168414698-0a330065-7b48-428c-a243-59eea0d4b8a4.png)

- P(x)는 특정 클래스에 속하지 않은 특징의 분포에 따라 값이 계산되므로 상수로 처리할 수 있음

- 사전 확률과 유사 기능도를 이용해 사후 확률을 계산할 수 있음

  ![image-20220514155447172](https://user-images.githubusercontent.com/102509786/168414699-df700ccb-8d42-4aa8-9ab7-c540ee0868b2.png)

- 라플라스 스무딩 (Laplace Smooting) : 특징의 출현 횟수 초기값을 1부터 시작해 0을 곱해 발생하는 문제를 해결(발견되지 않은 특징의 출현 빈도 초기값을 1로 설정)