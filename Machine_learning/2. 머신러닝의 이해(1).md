# 2. 머신러닝의 이해(1)

## Scikit-Learn 라이브러리

- 머신러닝 알고리즘을 구현한 오픈소스 라이브러리 중 가장 유명한 라이브러리 중 하나
- 일관되고 간결한 API가 강점이며, 문서화가 잘 되어있음
- 알고리즘은 파이썬 클래스로 구현되고, 데이터 셋은 Numpy 배열, Pandas DataFrame, Scipy 희소행렬을 사용할 수 있음



## Scikit-Learn의 데이터 표현 방식

 ### 특징 행렬(Feature Matrix)

- 표본(sample)은 데이터 셋이 설명하는 개별 객체를 나타냄

- 특징(feature)은 각 표본을 연속적인 수치값, 부울값, 이산값으로 표현하는 개별 관측치를 의미

- 표본 -> 행렬의 행

- 행의 갯수 -> n_samples

- 특징(feature) -> 행렬의 열

- 열의 갯수 -> n_features

- 관례적으로 특징행렬은 변수 X에 저장

- [n_samples, n_features] 형태의 2차원 배열 구조를 사용

  (주로 Numpy 배열, Pandas DataFrame, Scipy 희소행렬을 사용)

### 대상 벡터(Target Vector)

- 연속적인 수치값, 이산 클래스/레이블을 가짐
- 길이 -> n.samples
- 관례적으로 대상벡터는 변수 y에 저장
- 1차원 배열 구조를 사용 (주로 Numpy 배열, Pandas Series를 사용)
- 특징 행렬로부터 예측하고자 하는 값의 벡터
- 종속 변수, 출력 변수, 결과 변수, 반응 변수 라고도 함



> Numpy 배열을 이용한 특징 행렬(X), 대상 벡터(y)의 생성

```python
import numpy as np

rs = np.random.RandomState(10) #Seed값 고정
x = 10 * rs.rand(5)
y = 2 * x - 1 * rs.rand(5)
x.shape, y.shape
#((5,), (5,))
```

```python
X = x.reshape(-1, 1)
X.shape
# (5, 1)
```



## Scikit-Learn Estimator API 기본 활용 절차

1. 데이터 준비
2. 모델 클래스 선택
3. 모델 인스턴스 생성과 하이퍼파라미터 선택
4. 특징 행렬과 대상 벡터 준비
5. 모델을 데이터에 적합
6. 새로운 데이터를 이용해 예측
7. 모델 평가

### 1. 데이터 준비

``` python
import numpy as np
import matplotlib.pyplot as plt
rs = np.random.RandomState(10)
x = 10 * rs.rand(100)
y = 3 * x + 2 * rs.rand(100)
plt.scatter(x, y, s=10) # size=10
```

![image-20220502213040747](https://user-images.githubusercontent.com/102509786/166445962-af9d54c9-a0b1-4222-ab85-5de2f91404b8.png)
### 2. 모델 클래스 선택

### 3. 모델 인스턴스 생성과 하이퍼파라미터 선택

```python
from sklearn.linear_model import LinearRegression
regr = LinearRegression() # 선형회귀 객체(인스턴스) 생성 - 디폴트
```

```python
from sklearn.linear_model import LinearRegression
regr = LinearRegression(fit_intercept=True) #선형회귀 객체(인스턴스) 생성 - fit_intercept=True라는 하이퍼파라미터 제공
```

### 4. 특징 행렬과 대상 벡터 준비

```python
X = x.reshape(-1, 1)
X.shape, y.shape
#((100, 1), (100,))
```

### 5. 모델을 데이터에 적합

```python
regr.fit(X, y) # X, y에 맞는 선형회귀 모델을 적합
```

```python
Regr.coef_ #모델의 기울기
# array([2.985507])
```

```python
regr.intercept_ # 모델의 y절편
# 0.987853434
```

### 6. 새로운 데이터를 이용해 예측

```python
x_new = np.linspace(-1, 11, num=100)
```

```python
X_new = x_new.reshape(-1, 1)
X_new.shape
# (100, 1)
```

```python
y_pred = regr.predict(X_new) # 새로 입력된 X_new에 대한 모델 예측값(y_pred) 생성
```

```python
plt.plot(x_new, y_pred, c='red')
plt.scatter(x, y, s=10)
```

![image-20220502213058025](https://user-images.githubusercontent.com/102509786/166445972-123c4881-c29b-49f7-af73-b7d0e2c3574e.png)

### 7. 모델 평가

```python
from sklearn.metrics import mean_squared_error

rmse = np.sqrt(mean_sqared_error(y, y_pred)) #RMSE(평균제곱오차) 구하기, y: 실제값, y_pred: 예측값
rmse
#13.708237122486333
```



## 훈련 데이터와 테스트 데이터

### 훈련 데이터와 테스트 데이터의 분리

- 머신러닝 모델을 만들 때 사용한 데이터는 모델의 성능측정용으로 사용하지 않음 -> 일반화 문제
- 훈련 데이터 : 머신러닝 모델을 만들 목적으로 사용
- 테스트 데이터 : 머신러닝 모델이 잘 작동하는지를 측정할 목적으로 사용
- scikit-learn의 train_test_split 함수를 주로 사용 (기본적으로 훈련용 75%, 테스트용 25% 구성)

```python
from sklearn.model_selection import train_test_split

X = iris.data
y = iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25) # random_state : 데이터 재현을 위한 seed 값

X_train.shape, y_train.shape, X_test.shape, y_test.shape
# ((120,4), (120,), (30, 4), (30,))
```

```python
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborClassifier(n_neighbors=1)
knn.fit(X_train, y_train)
```

테스트 데이터를 이용한 모델의 성능 측정

```python
y_pred = knn.predict(X_test) # 테스트 데이터로 예측 수행
y_pred
# array([0, 2, 2, 1, 2, 1, 2, 0, 1, 1, 0, 0, 0, 1, 0, 1, 2, 2, 1, 1, 1, 1, 1, 0, 0, 2, 1, 2, 2, 0])
```

```python
np.mean(y_test == y_pred) # 테스트 데이터의 실제값과 예측값 비교를 통해 정확도 계산
# 0.9 
```

```python
knn.score(X_test, y_test) # 모델 정확도 계산
# 0.9
```

```python
from sklearn.metrics import accuracy_score # 모델 정확도 계산

accuracy_score(y_test, y_pred)
# 0.9
```

## 하이퍼 파라미터의 선택

```python
train_accuracy = []
test_accuracy = []
neighbors = range(1, 11)
for n in neighbors:
    knn = KNeighborsClassifier(n_neighbors=n) # Neighbors를 1~11까지 번갈아가며 설정해서 모델 적합 및 정확도 계산
    knn.fit(X_train, y_train)
    train_accuracy.append(knn.score(X_train, y_train))
    test_accuracy.append(knn.score(X_test, y_test))
```

```python
import matplotlib.pyplot as plt

plt.plot(neighbors, train_accuracy, label='train accuracy')
plt.plot(neighbors, test_accuracy, label='test accuracy')
plt.xlabel('n_neighbors')
plt.ylabel('accuracy')
plt.legend()
```

![image-20220502213119254](https://user-images.githubusercontent.com/102509786/166445982-74910189-62f8-4302-b4d0-741ba3ebf35e.png)

파라미터를 변경해가면서 가장 높은 정확도를 보이는 모델 생성을 위한 하이퍼파라미터 선택 가능



## 주요 정리

1. scikit-learn은 데이터를 담고있는 2차원 구조의 특징행렬(X)와 레이블을 담고 있는 1차원 구조의 대상 벡터 (y)를 사용하도록 설계되어 있다.
2. scikit-learn의 Estimator는 공통 인터페이스로 fit, predict, score 메소드를 제공한다.
3. 회귀 문제는 선형 알고리즘이 구현되어 있는 LinearRegressor를 사용할 수 있고, 분류 문제는 분류 알고리즘이 구현되어 있는 KNeighborsClassifier를 사용할 수 있다.
4. scikit-learn의 train_test_split 함수를 이용해 훈련 데이터와 테스트 데이터를 나누고, 모델의 성능은 테스트 데이터를 이용해 측정한다.
