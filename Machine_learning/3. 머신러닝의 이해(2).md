# 3. 머신러닝의 이해(2)



## 교차 검증

### 교차 검증의 기본 절차와 필요성

- 교차 검증의 기본 절차:

  1. 교차 검증 1단계에서는 데이터를 학습용과 테스트용으로 나눔
  2.  모델의 테스트 성능을 기록
  3. 교차 검증의 매 단계마다 다른 파티션으로 위의 작업을 수행
  4. 모델의 최종 성능은 매 단계의 테스트 성능을 평균 계산

- 교차 검증은 모델의 변동성을 줄여주며 오버피팅과 같은 문제를 막아줌 

  교차 검증을 통해 모든 데이터를 학습용 데이터로 사용할 수 있음



### 교차 검증 기법

- k 폴드 교차 검증:

  데이터를 무작위로 k개의 동일한 크기인 폴드로 나눔. (보통 k값으로 3, 5, 10을 많이 사용)

  각 시행 단계에서 특정 폴드를 테스트용으로, 나머지는 학습용으로 사용

  각 폴드를 테스트 세트로 한 번씩 사용하고 이 과정을 k번 반복 시행함

  최종적으로 모델 성능의 평균을 계산

  ```python
  from sklearn.datasets import load_iris
  iris = load_iris()
  X = iris.data
  y = iris.target
  ```

  ```python
  from sklearn.neighbors import KNeighborsClassifier
  model = KNeighborsClassifier(n_neighbors=1)
  ```

  ```python
  from sklearn.model_selection import cross_val_score
  cross_val_score(model, X, y, cv=5) #교차검증 수행, (cv=5 ;5번 반복)
  # array([0.96666667, 0.96666667, 0.93333333, 0.933333333, 1.		])
  ```



## 최적의 모델

### 최적의 모델 선택 방법

- 모델의 성능이 기대에 못 미칠 경우 어떻게 개선할 것인가?
  - 더 복잡하거나 더 유연한 모델을 사용
  - 덜 복잡하거나 덜 유연한 모델을 사용
  - 더 많은 훈련 표본을 수집
  - 각 표본에 특징을 추가하기 위해 더 많은 데이터를 수집



## 편향-분산 트레이드오프

### 고편향 모델과 고분산 모델

- 언더피트 : 과소적합. 모델이 고편향됨. 모델이 모든 특징을 적절히 설명할 수 있을 만큼 모델 유연성이 충분치 않음

![image-20220503210652003](https://user-images.githubusercontent.com/102509786/166454295-b2a9c258-8ea6-4e3e-9939-a3836bae89bc.png)

> 1차 함수로는 모델을 설명하기에 유연성이 충분하지 않음.



- 오버피트 : 과대적합. 모델이 고분산됨. 모델이 모든 특징을 세밀하게 설명할 수 있을 만큼 모델 유연성이 충분하지만,  훈련 데이터의 잡음까지 반영하고 있음

![image-20220503210803462](https://user-images.githubusercontent.com/102509786/166454299-d7b86b71-c696-4f92-aca7-dc759910dc94.png)

```python
from sklearn.preprocessing import PolynomialFeatures #모델 복잡도 조절기능 있음
from sklearn.linear_model import LinearRegression
from sklearn.pipline import make_pipline # pipline에 등록하면 객체들이 seamless하게 수행되기 때문에 생산성이 높아짐

def PolynomialRegression(degree=2, **kwargs):
    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))
```

```python
import numpy as np

def make_data(N, err=1.0, seed=1):
    np.random.seed(seed)
    X = np.random.rand(N, 1) ** 2
    y = 10 - 1. / (X.ravel() + 0.1)
    if err > 0:
        y += err * np.random.randn(N)
    return X, y

X, y = make_data(40)
```

```python
import matplotlib.pyplot as plt

plt.style.use("seaborn-whitegrid")

X_test = np.linspace(-0.1, 1.1, 500).reshape(-1, 1)

fig = plt.figure(figsize=(12, 10))
for i, degree in enumerate([1, 3, 5, 10], start=1):
    ax = fig.add_subplot(2, 2, i)
    ax.scatter(X.ravel(), y, s=15)
    y_test = make_pipline(PolynomialFeatures(degree), LinearRegression()) # 차수를 1, 3, 5, 10으로 조정해가면서 선형회귀 모델을 적합시킴
    ax.plot(X_test.ravel(), y_test, label="degree={0}".format(degree))
    ax.set_xlim(-0.1, 1.0)
    ax.set_ylim(-2, 12)
    ax.legend(loc='best')
```

![image-20220503211843974](https://user-images.githubusercontent.com/102509786/166454306-29630d77-5f64-4528-9dc6-441985264feb.png)



### 검증곡선

- 편향과 분산 사이의 트레이드오프에서 가장 효율적인 지점 -> 최적의 모델

![image-20220503211933481](https://user-images.githubusercontent.com/102509786/166454312-8fa8b7d3-8fc4-4dfa-aa4a-5d7ec0242c34.png)

- 편향과 분산 사이의 최적의 트레이드 오프 -> 3차 다항식

```python
plt.figure(figsize=(8, 7))
plt.scatter(X.ravel(), y)
lim = plt.axis()
y_test = PolynomialRegression(3).fit(X, y).predict(X_test)
plt.plot(X_test.ravel(), y_test)
plt.axis(lim)
```

![image-20220503212226242](https://user-images.githubusercontent.com/102509786/166454347-d8dd3b9c-cb16-4489-b951-93361f281c17.png)



## 학습곡선

### 학습곡선

- 최적의 모델은 훈련 데이터의 규모에도 의존함

![image-20220503212312219](https://user-images.githubusercontent.com/102509786/166454382-103dcd94-b5ca-43ce-a1b5-44a7d0f7f0f2.png)

![image-20220503212316621](https://user-images.githubusercontent.com/102509786/166454395-bd8289b4-fb3a-4dfb-b820-0dd0e7dc60ec.png)

> 데이터 규모 증가에 따라 학습곡선도 변화함



- 학습곡선 : 훈련집합의 크기에 따른 훈련점수/ 검증점수의 플롯

![image-20220503212430587](https://user-images.githubusercontent.com/102509786/166454406-3486c0d4-0ada-403f-aad6-8f98156851b8.png)

학습곡선과 검증 곡선이 수렴하는 것은 데이터 규모가 커져도 개선의 효과를 보이지 않는 지점을 의미



## 그리드 서치

### 최적의 다항식 모델을 구하기 위한 GridSearchCV

```python
from sklearn.model_selection import GridSearchCV

param_grid = {'polynomialfeatures__degree': np.arange(21), 
             'linearregression__fit_intercept': [True, False], 
             'linearregression__nomalize': [True, False]} # 선형회귀에 사용되는 각종 파라미터의 다양한 값들을 미리 세팅
grid = GridSearchCV(PolynomialRegression(), param_grid, cv=7) # 7겹의 교차검증을 수행
```

```python
grid.fit(X, y)
```

```python
grid.best_params_ # 최적의 파라미터 값을 출력
# {'linearregression__fit_intercept': False,'linearregression__nomallize': [True, False], 'polynomialfeatures__degree': 4}
```

그리드서치 : 검증 점수를 최대화 하는 모델을 찾아나는 자동화 도구

### 최적 모델과 데이터 적합

```python
model = grid.best_estimator_ # 최적의 모델 객체

plt.figure(figsize=(8,7))
plt.scatter(X.ravel(), y)
lim = plt.axis()
y_test = model.fit(X, y).predict(X_test)
plt.plot(X_test.ravel(), y_test)
plt.axis(lim)
```

![image-20220503213303622](https://user-images.githubusercontent.com/102509786/166454418-64719dca-ec82-4633-bca9-281d5e0c006b.png)



## 주요 정리

1. 교차검증을 사용하면 모델을 훈련시킬 데이터를 빠트릴 수 있는 문제를 방지할 수 있다.
2. 검증곡선을 시각화하면 모델의 복잡과 관련된 편향과 분산 사이의 트레이드오프에서 적절한 지점을 확인할 수 있다.
3. 학습곡선 플롯을 이용하면 훈련집합의 크기에 따른 훈련 점수와 검증 점수의 변화를 시각적으로 확인할 수 있다.
4. 그리드 서치 자동화 도구를 이용하면 검증 점수를 최대화하는 최적의 모델을 찾아 데이터에 적합시킬 수 있다.